{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#우선 Link prediction의 정의부터 다시 잡고 넘어가자.\n",
    "#왜 node classification에 대한 정의는 생략했냐면, 석사과정 연구를 모두 다 node classification에 대해서 진행했고 머릿속에 개념이 잘 잡혀있어서 생략하고 넘어갔다.\n",
    "#하지만 link prediction은 예전에 공부하고 까먹었기 때문에 다시 한번 잡고 이어서 heterogeneous graph에서 link prediction이 어떻게 진행되는지 알아보자\n",
    "\n",
    "#Link prediction의 개념 \n",
    "#링크 예측은 현재 네트워크(graph)에서 나타나지 않은 연결을 예측하거나 미래의 네트워크에서 새롭게 생겨나거나 없어지는 것을 예측하는 것이다.  \n",
    "#일반적으로는 공통된 이웃(common neighbor nodes)의 수와 같은 그래프 지표를 활용해서 관측되지 않은 링크를 찾아낸다.\n",
    "#그러면 일반적인 인공지능 모델들과 비슷하게 train , valid , test set으로 나눠야하는데 link를 예측하는것이므로 일종의 subgraph가 들어간다 라고 생각하면 된다. (train edge로만 이루어진 그래프로 학습을 진행하고 test edge에 대한 링크를 추론해봄)\n",
    "#또한 positive, negative 로 나누는데, 이는 positive는 연결되어있는데 추후에 어떻게 될것인지에 대한 추측을 하기 위해서 연결되어있는것들, negative는 연결이 안되어있는데 추후에 어떻게 될것인지에 대한 추측을 위해 연결이 안되어있는 쌍들을 나타낸다. \n",
    "#이 두가지를 고려해서 좀 더 좋은 성능을 보인다고 한다.\n",
    "#우선 데이터셋은 임의로 만들어보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\HOME\\.dgl\\cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
      "Extracting file to C:\\Users\\HOME\\.dgl\\cora_v2_d697a464\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "tensor([   0,    0,    0,  ..., 2707, 2707, 2707]) tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import dgl\n",
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "\n",
    "g = dataset[0]\n",
    "\n",
    "src,dst = g.edges()\n",
    "print(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test 나눠줌 예제라서 validation은 추가하지 않겠음\n",
    "eids = np.arange(g.num_edges())\n",
    "eids = np.random.permutation(eids)\n",
    "test_size = int(len(eids)*0.1) #1055개를 test set으로 사용\n",
    "\n",
    "train_size = g.num_edges() - test_size\n",
    "test_pos_src, test_pos_dst = src[eids[:test_size]], dst[eids[:test_size]]\n",
    "train_pos_src, train_pos_dst = src[eids[test_size:]], dst[eids[test_size:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=2708, num_edges=9501,\n",
      "      ndata_schemes={'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'label': Scheme(shape=(), dtype=torch.int64), 'feat': Scheme(shape=(1433,), dtype=torch.float32)}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "#위에서 test와 train을 구분해주었고 이제 negative sampling을 해준다\n",
    "import scipy.sparse as sp\n",
    "\n",
    "adj = sp.coo_matrix((np.ones(len(src)),(src.numpy(),dst.numpy())))\n",
    "#coo_matrix(data,(row,col)) row와 col에 동시에 나타나면 1로 만들어 인접행렬 생성\n",
    "adj_neg = 1- adj.todense()\n",
    "neg_src, neg_dst = np.where(adj_neg !=0) #연결 안되어있는 노드 쌍 추출\n",
    "\n",
    "#negative sampling 숫자는 많을 수 밖에 없음 연결되어있지 않은 모든 상황을 고려하기 때문에\n",
    "neg_eids = np.random.choice(len(neg_src),g.num_edges()//2)\n",
    "test_neg_u, test_neg_v = neg_src[neg_eids[:test_size]], neg_dst[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_src[neg_eids[test_size:]], neg_dst[neg_eids[test_size:]]\n",
    "\n",
    "train_g = dgl.remove_edges(g, eids[:test_size])\n",
    "print(train_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "import torch.nn.functional as F\n",
    "import dgl.function as fn\n",
    "import torch.nn as nn\n",
    "#graph sage를 사용해서 구축할 예정임.\n",
    "#graphsage가 inductive한 환경에서 실행될 수 있기도하고 빠르기도 하기 때문에 baseline으로 설정함\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self,in_feats,hidden_feats):\n",
    "        super(GraphSAGE,self).__init__()\n",
    "\n",
    "        self.in_feats = in_feats\n",
    "        self.hidden_feats = hidden_feats\n",
    "\n",
    "        self.sage1 = SAGEConv(in_feats, hidden_feats, aggregator_type = 'mean')\n",
    "        self.sage2 = SAGEConv(hidden_feats,hidden_feats,aggregator_type='mean')\n",
    "    def forward(self,g,features):\n",
    "        h = self.sage1(g,features)\n",
    "        h = F.relu(h)\n",
    "        h = self.sage2(g,h)\n",
    "        return h\n",
    "    \n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self,g,features):\n",
    "        with g.local_scope():\n",
    "            g.ndata['feat'] = features\n",
    "            g.apply_edges(fn.u_dot_v('feat','feat','score'))\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 5, loss: 0.6116\n",
      "In epoch 10, loss: 0.5949\n",
      "In epoch 15, loss: 0.5647\n",
      "In epoch 20, loss: 0.5188\n",
      "In epoch 25, loss: 0.4516\n",
      "In epoch 30, loss: 0.3904\n",
      "In epoch 35, loss: 0.3636\n",
      "In epoch 40, loss: 0.3268\n",
      "In epoch 45, loss: 0.2971\n",
      "In epoch 50, loss: 0.2732\n",
      "AUC 0.8763244311673144\n"
     ]
    }
   ],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
    "\n",
    "pred = DotPredictor()\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def criterion(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    labels = labels.unsqueeze(1)\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def accuracy(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    #labels = labels.unsqueeze(1)\n",
    "\n",
    "    return roc_auc_score(labels, scores)\n",
    "    \n",
    "all_logits = []\n",
    "train_pos_g = dgl.graph((train_pos_src,train_pos_dst))\n",
    "train_neg_g = dgl.graph((train_neg_u,train_neg_v))\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.01)\n",
    "for epoch in range(50):\n",
    "    h = model(train_g, train_g.ndata['feat'])\n",
    "    pos_score = pred(train_pos_g, h)\n",
    "    neg_score = pred(train_neg_g, h)\n",
    "    loss = criterion(pos_score, neg_score)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 5 == 0 :\n",
    "        print(f'In epoch {epoch+1}, loss: {loss:.4f}')\n",
    "test_pos_g = dgl.graph((test_pos_src,test_pos_dst))\n",
    "test_neg_g = dgl.graph((test_neg_u,test_neg_v))\n",
    "h = model(train_g,train_g.ndata['feat'])\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', accuracy(pos_score, neg_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
