{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['disease', 'drug', 'gene']\n",
      "['interacts', 'interacts', 'treats']\n",
      "[('drug', 'interacts', 'drug'), ('drug', 'interacts', 'gene'), ('drug', 'treats', 'disease')]\n"
     ]
    }
   ],
   "source": [
    "# Create a heterograph with 3 node type and 3 edge type\n",
    "graph_data = {\n",
    "    ('drug','interacts','drug'): (torch.tensor([0,1]), torch.tensor([1,2])),\n",
    "    ('drug','interacts','gene'): (torch.tensor([0,1]), torch.tensor([2,3])),\n",
    "    ('drug','treats','disease'): (torch.tensor([1]), torch.tensor([2]))\n",
    "}\n",
    "# 이 코드의 뜻은 drug node type이 interacts라는 엣지타입을 가지고 drug 노드 타입과 연결된것\n",
    "# drug node type이 interacts라는 엣지타입을 가지고 gene 노드 타입과 연결된것\n",
    "# drug node type이 treats 엣지 타입을 가지고 disease 노드 타입과 연결된 것을 나타낸다.\n",
    "g = dgl.heterograph(graph_data)\n",
    "print(g.ntypes)\n",
    "print(g.etypes)\n",
    "print(g.canonical_etypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'disease': 3, 'drug': 3, 'gene': 4},\n",
      "      num_edges={('drug', 'interacts', 'drug'): 2, ('drug', 'interacts', 'gene'): 2, ('drug', 'treats', 'disease'): 1},\n",
      "      metagraph=[('drug', 'drug', 'interacts'), ('drug', 'gene', 'interacts'), ('drug', 'disease', 'treats')])\n"
     ]
    }
   ],
   "source": [
    "#즉 일반적으로 먼저 공부하는 homogeneous graph와 bipartite graph는 엣지 관계가 1개인 heterogeneous graph이다\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "3\n",
      "tensor([0, 1, 2])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "#노드와 엣지가 여러 타입이 사용되는 경우에는 타입을 명시해줘야지 정보를 얻을 수 있다.\n",
    "print(g.num_nodes())\n",
    "print(g.num_nodes('drug'))\n",
    "# print(g.nodes()) -> error\n",
    "print(g.nodes('drug'))\n",
    "print(g.nodes('gene'))\n",
    "print(g.nodes('disease'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "tensor([[0.]])\n"
     ]
    }
   ],
   "source": [
    "#node or edge type에 대한 features 설정하기\n",
    "g.nodes['drug'].data['dx'] = torch.ones(3,1)\n",
    "print(g.nodes['drug'].data['dx'])\n",
    "\n",
    "g.edges['treats'].data['ex'] = torch.zeros(1,1)\n",
    "print(g.edges['treats'].data['ex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes={'item': 500, 'user': 1000},\n",
      "      num_edges={('item', 'clicked-by', 'user'): 5000, ('item', 'disliked-by', 'user'): 500, ('user', 'click', 'item'): 5000, ('user', 'dislike', 'item'): 500, ('user', 'follow', 'user'): 3000, ('user', 'followed-by', 'user'): 3000},\n",
      "      metagraph=[('item', 'user', 'clicked-by'), ('item', 'user', 'disliked-by'), ('user', 'item', 'click'), ('user', 'item', 'dislike'), ('user', 'user', 'follow'), ('user', 'user', 'followed-by')])\n"
     ]
    }
   ],
   "source": [
    "# heterogeneous graph에서 message passing은 각 관계에 대한 메세지 전달 \n",
    "# 각 노드 타입에 대한 모든 집계 결과를 합치는 축약으로 이루어져있다.\n",
    "# 그러면 본격적으로 실습에 들어가보자\n",
    "\n",
    "import numpy as np\n",
    "n_users = 1000 #user 1000명\n",
    "n_items = 500 #item 500개\n",
    "n_follows = 3000 #follows 3000\n",
    "n_clicks = 5000 #클릭데이터 5000개\n",
    "n_dislikes = 500 #싫어요 500개\n",
    "n_hetero_features = 10\n",
    "n_user_classes = 5 # user label\n",
    "n_max_clicks = 10 # clik label\n",
    "\n",
    "follow_src = np.random.randint(0,n_users, n_follows)\n",
    "follow_dst = np.random.randint(0,n_users, n_follows)\n",
    "click_src = np.random.randint(0,n_users,n_clicks) #user idx에서 click 어디에 했는지 즉 5000개\n",
    "click_dst = np.random.randint(0,n_items,n_clicks) #위에 user에서 어떤 아이템인지\n",
    "dislike_src = np.random.randint(0,n_users,n_dislikes)\n",
    "dislike_dst = np.random.randint(0,n_items,n_dislikes)\n",
    "hetero_graph = dgl.heterograph({\n",
    "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
    "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
    "    ('user', 'click', 'item'): (click_src, click_dst),\n",
    "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
    "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
    "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})\n",
    "\n",
    "print(hetero_graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heterogeneous graph의 각 노드 feature와 user의 클래스(노드분류), click edge의 라벨을 설정해준다.\n",
    "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users,n_hetero_features)\n",
    "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items,n_hetero_features)\n",
    "hetero_graph.nodes['user'].data['label'] = torch.randint(0,n_user_classes,(n_users,))\n",
    "hetero_graph.edges['click'].data['label'] = torch.randint(1,n_max_clicks,(n_clicks,)).float()\n",
    "hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6)\n",
    "hetero_graph.edges['click'].data['train_mask'] = torch.zeros(n_clicks, dtype=torch.bool).bernoulli(0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.nn as dglnn\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "# heterogeneous graph를 처리할 수 있는 모델 정의\n",
    "# 각 관계별로 따로 처리해야되기 때문에 rel_names인자로 받는다.\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        self.conv2 = dglnn.HeteroGraphConv({\n",
    "            rel: dglnn.GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'item': tensor([[ 0.4085, -0.3442, -0.2905, -0.3642, -0.4166],\n",
      "        [ 0.4111, -0.4494, -0.0868, -0.3961,  0.1084],\n",
      "        [ 0.2562, -0.2515, -0.1196, -0.6014,  0.1129],\n",
      "        ...,\n",
      "        [ 0.4015, -0.2884, -0.8815,  0.2217,  0.4844],\n",
      "        [ 0.0602, -0.2743,  0.0055, -0.0050,  0.1593],\n",
      "        [ 0.1573, -0.4735, -0.1770, -0.2468,  0.2824]], grad_fn=<SumBackward1>), 'user': tensor([[ 9.1826e-01, -1.0417e-01,  5.0676e-01, -8.6102e-01, -6.0579e-01],\n",
      "        [ 3.1130e-01, -7.8602e-02,  8.4745e-01, -1.2497e-01,  3.9142e-01],\n",
      "        [ 6.6147e-01,  3.7854e-01,  3.9091e-01, -6.6784e-04, -8.7747e-02],\n",
      "        ...,\n",
      "        [ 6.4095e-01, -6.5442e-01, -3.9604e-01,  6.6888e-01, -1.3066e-01],\n",
      "        [ 6.6090e-01, -3.9749e-01,  7.9074e-01,  4.4164e-03, -9.9020e-02],\n",
      "        [ 1.1888e-01, -2.8105e-01,  1.2480e+00,  3.4606e-01, -4.8740e-01]],\n",
      "       grad_fn=<SumBackward1>)}\n"
     ]
    }
   ],
   "source": [
    "#위의 모델에서 dgl.nn.HeteroGraphConv 는 노드의 타입들과 노드 피쳐 텐서를 받아서 각 타입의 변화한 값을 리턴해준다.\n",
    "model = RGCN(n_hetero_features,32,n_user_classes,hetero_graph.etypes)\n",
    "#마지막의 hetero_graph.etypes를 넣어줌으로서 관계별로 학습할 수 있다.\n",
    "user_feats = hetero_graph.nodes['user'].data['feature']\n",
    "item_feats = hetero_graph.nodes['item'].data['feature']\n",
    "labels = hetero_graph.nodes['user'].data['label']\n",
    "train_mask = hetero_graph.nodes['user'].data['train_mask']\n",
    "\n",
    "node_features = {'user':user_feats,'item':item_feats}\n",
    "# 1회 foward process했을 때를 보여준다\n",
    "h_dict = model(hetero_graph,node_features)\n",
    "h_user = h_dict['user']\n",
    "h_item = h_dict['item']\n",
    "print(h_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.4209, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.4051, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3703, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3402, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.3213, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2975, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2694, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2247, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.2020, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1769, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1540, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1337, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.1120, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0885, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0664, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0458, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0246, grad_fn=<NllLossBackward0>)\n",
      "tensor(1.0025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9817, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.9009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8615, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.8040, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7659, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.7095, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6912, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6727, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6545, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6368, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6190, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5347, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5184, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4869, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4565, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4418, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "epochs = 50\n",
    "for i in range(epochs):\n",
    "    model.train()\n",
    "    logits = model(hetero_graph,node_features)['user']\n",
    "    loss = F.cross_entropy(logits[train_mask],labels[train_mask])\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "#학습방법은 일반적인것과 같고 logits에 user를 써놓은 이유는 user의 클래스에만 관심이 있기 때문이다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
